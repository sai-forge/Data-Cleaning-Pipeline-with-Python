{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31717be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cleaning_pipeline.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "class DataCleaningPipeline:\n",
    "    \"\"\"\n",
    "    A reusable data‐cleaning pipeline that provides methods to:\n",
    "      - Load data from CSV (or pass a DataFrame directly)\n",
    "      - Remove duplicates\n",
    "      - Handle missing values (drop or impute)\n",
    "      - Standardize column names\n",
    "      - Correct data types\n",
    "      - Detect and handle outliers\n",
    "      - Run all steps in sequence via run()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df=None, csv_path=None, excel_path=None):\n",
    "        \"\"\"\n",
    "        Initialize the pipeline. Provide either:\n",
    "          - df: a pandas DataFrame,\n",
    "            - excel_path: path to an Excel file to load or\n",
    "          - csv_path: path to a CSV file to load.\n",
    "        \"\"\"\n",
    "        if df is not None:\n",
    "            self.df = df.copy()\n",
    "        elif csv_path is not None:\n",
    "            self.df = pd.read_csv(csv_path)\n",
    "        elif excel_path is not None:\n",
    "            self.df = pd.read_excel(excel_path)\n",
    "        else:\n",
    "            raise ValueError(\"You must provide either a DataFrame (df), csv_path or excel_path.\")\n",
    "\n",
    "        # Store intermediate states if needed\n",
    "        self._original_df = self.df.copy()\n",
    "\n",
    "    def check_duplicates(self):\n",
    "        \"\"\"\n",
    "        Returns the number of duplicate rows in the DataFrame.\n",
    "        \"\"\"\n",
    "        return self.df.duplicated().sum()\n",
    "\n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"\n",
    "        (Full Row Matches)\n",
    "        Remove duplicate rows from the DataFrame while keeping the first occurance.\n",
    "        Optionally specify subset of columns and which duplicate to keep.\n",
    "        \"\"\"\n",
    "        self.df.drop_duplicates(inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    def standardize_column_names(self, lowercase=True, strip_whitespace=True, replace_spaces=\"_\"):\n",
    "        \"\"\"\n",
    "        Normalize column names for consistency:\n",
    "          - lowercase: convert all to lowercase\n",
    "          - strip_whitespace: remove leading/trailing whitespace\n",
    "          - replace_spaces: character to replace spaces with (e.g. '_')\n",
    "        \"\"\"\n",
    "        new_cols = []\n",
    "        for col in self.df.columns:\n",
    "            new_col = col\n",
    "            if strip_whitespace:\n",
    "                new_col = new_col.strip()\n",
    "            if lowercase:\n",
    "                new_col = new_col.lower()\n",
    "            if replace_spaces:\n",
    "                new_col = new_col.replace(\" \", replace_spaces)\n",
    "            new_cols.append(new_col)\n",
    "        self.df.columns = new_cols\n",
    "        return self.df\n",
    "\n",
    "    def convert_dtypes(self, dtype_map):\n",
    "        \"\"\"\n",
    "        Convert columns to specified dtypes.\n",
    "        - dtype_map: dictionary {col_name: target_dtype}, e.g. {'amount': 'float', 'order_date': 'datetime64'}.\n",
    "        \"\"\"\n",
    "        for col, dtype in dtype_map.items():\n",
    "            try:\n",
    "                if dtype.startswith(\"datetime\"):\n",
    "                    self.df[col] = pd.to_datetime(self.df[col], errors=\"coerce\")\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].astype(dtype, errors=\"ignore\")\n",
    "            except Exception as e:\n",
    "                # Fallback to using to_numeric when dtype is numeric but conversion fails\n",
    "                if dtype in (\"int\", \"float\", \"numeric\"):\n",
    "                    self.df[col] = pd.to_numeric(self.df[col], errors=\"coerce\")\n",
    "                else:\n",
    "                    raise\n",
    "        return self.df\n",
    "\n",
    "    def handle_missing(\n",
    "        self,\n",
    "        drop_threshold=0.5,\n",
    "        impute_strategy_numeric=\"median\",\n",
    "        impute_strategy_categorical=\"mode\",\n",
    "        missing_indicator=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Handle missing values in the DataFrame.\n",
    "        - drop_threshold: proportion (0–1) of allowed missing in a column; if missing% > drop_threshold, drop the column.\n",
    "        - impute_strategy_numeric: 'mean' or 'median' for numeric columns.\n",
    "        - impute_strategy_categorical: 'mode' for categorical columns.\n",
    "        - missing_indicator: if True, create boolean flag columns for each column that had missing values.\n",
    "        \"\"\"\n",
    "        # 1) Drop columns with too many missing\n",
    "        missing_pct = self.df.isnull().mean()\n",
    "        cols_to_drop = missing_pct[missing_pct > drop_threshold].index.tolist()\n",
    "        self.df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "        # 2) Optionally add missing-indicator flags\n",
    "        if missing_indicator:\n",
    "            for col in self.df.columns:\n",
    "                if self.df[col].isnull().any():\n",
    "                    self.df[f\"{col}_was_missing\"] = self.df[col].isnull().astype(int)\n",
    "\n",
    "        # 3) Impute numeric and categorical separately\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].dtype in [np.float64, np.int64]:\n",
    "                if impute_strategy_numeric == \"mean\":\n",
    "                    fill_value = self.df[col].mean()\n",
    "                else:\n",
    "                    fill_value = self.df[col].median()\n",
    "                self.df[col].fillna(fill_value, inplace=True)\n",
    "            else:\n",
    "                # Treat non-numeric as categorical/text\n",
    "                if impute_strategy_categorical == \"mode\":\n",
    "                    try:\n",
    "                        mode_val = self.df[col].mode(dropna=True)[0]\n",
    "                    except IndexError:\n",
    "                        mode_val = \"\"\n",
    "                    self.df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def detect_outliers_zscore(self, col_list=None, threshold=3.0, method=\"remove\"):\n",
    "        \"\"\"\n",
    "        Detect and handle outliers using the z-score method on numeric columns.\n",
    "        - col_list: list of columns to check; if None, uses all numeric columns.\n",
    "        - threshold: z-score threshold beyond which points are considered outliers.\n",
    "        - method: 'remove' to drop outlier rows, 'cap' to clip at threshold, or 'flag' to add a boolean column.\n",
    "        \"\"\"\n",
    "        numeric_cols = col_list or self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        for col in numeric_cols:\n",
    "            # Compute z-scores for the column\n",
    "            col_vals = self.df[col]\n",
    "            zscores = np.abs(stats.zscore(col_vals, nan_policy=\"omit\"))\n",
    "            outlier_mask = zscores > threshold\n",
    "\n",
    "            if method == \"remove\":\n",
    "                # Drop rows where this column is an outlier\n",
    "                self.df = self.df.loc[~outlier_mask].reset_index(drop=True)\n",
    "            elif method == \"cap\":\n",
    "                # Clip values at threshold * std dev from mean\n",
    "                mean_ = col_vals.mean()\n",
    "                std_ = col_vals.std()\n",
    "                upper = mean_ + threshold * std_\n",
    "                lower = mean_ - threshold * std_\n",
    "                self.df[col] = col_vals.clip(lower, upper)\n",
    "            elif method == \"flag\":\n",
    "                # Create a boolean indicator column for outliers\n",
    "                self.df[f\"{col}_outlier_flag\"] = outlier_mask.astype(int)\n",
    "            else:\n",
    "                raise ValueError(\"method must be one of ['remove','cap','flag']\")\n",
    "        return self.df\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        subset_duplicates=None,\n",
    "        keep_duplicates=\"first\",\n",
    "        lowercase_cols=True,\n",
    "        strip_whitespace=True,\n",
    "        replace_spaces=\"_\",\n",
    "        dtype_map=None,\n",
    "        drop_threshold=0.5,\n",
    "        impute_strategy_numeric=\"median\",\n",
    "        impute_strategy_categorical=\"mode\",\n",
    "        missing_indicator=True,\n",
    "        outlier_cols=None,\n",
    "        outlier_threshold=3.0,\n",
    "        outlier_method=\"remove\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Execute the full cleaning pipeline in sequence:\n",
    "          1. remove_duplicates\n",
    "          2. standardize_column_names\n",
    "          3. convert_dtypes (if dtype_map provided)\n",
    "          4. handle_missing\n",
    "          5. detect_outliers_zscore\n",
    "        Returns the cleaned DataFrame.\n",
    "        \"\"\"\n",
    "        # 1) Remove duplicates\n",
    "        self.remove_duplicates(subset=subset_duplicates, keep=keep_duplicates)\n",
    "\n",
    "        # 2) Standardize column names\n",
    "        self.standardize_column_names(\n",
    "            lowercase=lowercase_cols,\n",
    "            strip_whitespace=strip_whitespace,\n",
    "            replace_spaces=replace_spaces\n",
    "        )\n",
    "\n",
    "        # 3) Convert data types if a map is provided\n",
    "        if dtype_map:\n",
    "            self.convert_dtypes(dtype_map)\n",
    "\n",
    "        # 4) Handle missing values\n",
    "        self.handle_missing(\n",
    "            drop_threshold=drop_threshold,\n",
    "            impute_strategy_numeric=impute_strategy_numeric,\n",
    "            impute_strategy_categorical=impute_strategy_categorical,\n",
    "            missing_indicator=missing_indicator\n",
    "        )\n",
    "\n",
    "        # 5) Detect (and optionally remove/flag/cap) outliers\n",
    "        self.detect_outliers_zscore(\n",
    "            col_list=outlier_cols,\n",
    "            threshold=outlier_threshold,\n",
    "            method=outlier_method\n",
    "        )\n",
    "\n",
    "        return self.df\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
